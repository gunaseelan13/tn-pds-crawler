{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro-section"
      },
      "source": [
        "# TN PDS Crawler - Google Colab Runner\n",
        "\n",
        "This notebook allows you to run the Tamil Nadu PDS Crawler in Google Colab environment.\n",
        "\n",
        "## Features\n",
        "- Automatic setup of Chrome and ChromeDriver\n",
        "- Runs the crawler in headless mode\n",
        "- Saves results to Google Drive (optional)\n",
        "- Downloads results to your local machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## 1. Setup Environment\n",
        "\n",
        "First, let's install the required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install selenium webdriver-manager flask requests python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repo-section"
      },
      "source": [
        "## 2. Get the Code\n",
        "\n",
        "You can either clone the repository (if it's public) or upload the necessary files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone-repo"
      },
      "outputs": [],
      "source": [
        "# Option 1: Clone the repository (if it's public)\n",
        "!git clone https://github.com/gunaseelan13/tn-pds-crawler.git\n",
        "%cd tn-pds-crawler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload-files"
      },
      "outputs": [],
      "source": [
        "# Option 2: Upload files directly\n",
        "# Uncomment and run this cell if you prefer to upload files instead of cloning\n",
        "\n",
        "# from google.colab import files\n",
        "# print(\"Please upload the crawai_pds_selenium.py file:\")\n",
        "# uploaded = files.upload()\n",
        "# print(\"Please upload the shop_list.json file:\")\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chrome-section"
      },
      "source": [
        "## 3. Setup Chrome and ChromeDriver\n",
        "\n",
        "Google Colab comes with Chrome pre-installed, but we'll make sure it's properly configured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-chrome"
      },
      "outputs": [],
      "source": [
        "# Make sure Chrome is installed and get its version\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!chromium-browser --version\n",
        "!which chromium-browser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "directories-section"
      },
      "source": [
        "## 4. Create Directories\n",
        "\n",
        "Create necessary directories for output files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create-dirs"
      },
      "outputs": [],
      "source": [
        "# Create directories for output\n",
        "!mkdir -p data\n",
        "\n",
        "# Get current date for filename\n",
        "import datetime\n",
        "current_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "output_filename = f\"data/shop_status_results_{current_date}.json\"\n",
        "print(f\"Results will be saved to: {output_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "modify-crawler-section"
      },
      "source": [
        "## 5. Modify Crawler for Colab (Optional)\n",
        "\n",
        "We can optionally modify the crawler script to work better in Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "modify-crawler"
      },
      "outputs": [],
      "source": [
        "# This cell is optional - it adds some Colab-specific modifications to the crawler\n",
        "# Uncomment and run if you want to apply these changes\n",
        "\n",
        "'''\n",
        "import fileinput\n",
        "import sys\n",
        "\n",
        "# Add Colab-specific Chrome options\n",
        "with fileinput.FileInput(\"crawai_pds_selenium.py\", inplace=True) as file:\n",
        "    for line in file:\n",
        "        if \"chrome_options.add_argument(\\\"--headless\\\")\" in line:\n",
        "            print(line, end='')\n",
        "            print(\"        chrome_options.add_argument(\\\"--disable-dev-shm-usage\\\")  # Overcome limited resource problems in Colab\")\n",
        "            print(\"        chrome_options.add_argument(\\\"--no-sandbox\\\")  # Required in Colab\")\n",
        "        else:\n",
        "            print(line, end='')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run-crawler-section"
      },
      "source": [
        "## 6. Run the Crawler\n",
        "\n",
        "Now let's run the crawler with the appropriate options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-crawler"
      },
      "outputs": [],
      "source": [
        "# Run the crawler\n",
        "!python crawai_pds_selenium.py --shop-list-json shop_list.json --output-json $output_filename --headless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "google-drive-section"
      },
      "source": [
        "## 7. Save Results to Google Drive (Optional)\n",
        "\n",
        "You can save the results to Google Drive for persistence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-to-drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a directory in Google Drive if it doesn't exist\n",
        "!mkdir -p \"/content/drive/My Drive/TN_PDS_Crawler_Results\"\n",
        "\n",
        "# Copy the results to Google Drive\n",
        "!cp $output_filename \"/content/drive/My Drive/TN_PDS_Crawler_Results/\"\n",
        "print(f\"Results saved to Google Drive at: /content/drive/My Drive/TN_PDS_Crawler_Results/{output_filename.split('/')[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-section"
      },
      "source": [
        "## 8. Download Results\n",
        "\n",
        "Download the results to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-results"
      },
      "outputs": [],
      "source": [
        "# Download the results\n",
        "from google.colab import files\n",
        "files.download(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "debug-section"
      },
      "source": [
        "## 9. Debug Information\n",
        "\n",
        "If the crawler encounters issues, you can run these cells to get more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debug-info"
      },
      "outputs": [],
      "source": [
        "# Check if screenshots were saved\n",
        "!ls -la *.png\n",
        "\n",
        "# Check if page source was saved\n",
        "!ls -la *.html\n",
        "\n",
        "# Display one of the screenshots (if available)\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "screenshot_files = glob.glob(\"*.png\")\n",
        "if screenshot_files:\n",
        "    img = mpimg.imread(screenshot_files[0])\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Screenshot: {screenshot_files[0]}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No screenshots found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "schedule-section"
      },
      "source": [
        "## 10. Schedule Regular Runs (Advanced)\n",
        "\n",
        "Note: Google Colab has limitations on how long notebooks can run. For true scheduling, consider using GitHub Actions or a dedicated server.\n",
        "\n",
        "However, you can use this cell to run the crawler multiple times with delays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "schedule-runs"
      },
      "outputs": [],
      "source": [
        "# This is a simple scheduler that will run the crawler multiple times\n",
        "# Note: Colab will disconnect after a period of inactivity, so this is not a true scheduling solution\n",
        "'''\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# How many times to run\n",
        "runs = 3\n",
        "# Hours between runs\n",
        "hours_between = 1\n",
        "\n",
        "for i in range(runs):\n",
        "    print(f\"Run {i+1}/{runs} starting at {datetime.datetime.now()}\")\n",
        "    \n",
        "    # Generate filename with current timestamp\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_file = f\"data/shop_status_results_{current_time}.json\"\n",
        "    \n",
        "    # Run the crawler\n",
        "    !python crawai_pds_selenium.py --shop-list-json shop_list.json --output-json $output_file --headless\n",
        "    \n",
        "    # Copy to Google Drive if mounted\n",
        "    try:\n",
        "        !cp $output_file \"/content/drive/My Drive/TN_PDS_Crawler_Results/\"\n",
        "        print(f\"Saved to Google Drive\")\n",
        "    except:\n",
        "        print(\"Could not save to Google Drive - make sure it's mounted\")\n",
        "    \n",
        "    if i < runs - 1:  # Don't sleep after the last run\n",
        "        sleep_seconds = hours_between * 3600\n",
        "        print(f\"Sleeping for {hours_between} hours until next run...\")\n",
        "        time.sleep(sleep_seconds)\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
